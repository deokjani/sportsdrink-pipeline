name: Auto Deploy to EC2 on Push

on:
  push:
    branches:
      - main  # main 브랜치에 push 될 때만 작동

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ 코드 체크아웃
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2️⃣ EC2에서 Git 프로젝트 없으면 clone, 있으면 pull
      - name: Deploy via SSH (git clone & pull)
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            if [ ! -d ~/sportsdrink-pipeline-spark-airflow ]; then
              git clone https://github.com/deokjani/sportsdrink-pipeline-spark-airflow.git
            fi
            cd ~/sportsdrink-pipeline-spark-airflow
            git pull origin main

      # 3️⃣ .env 파일 생성 (로컬)
      - name: Create .env file
        run: |
          mkdir -p data_pipeline/docker
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> data_pipeline/docker/.env
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> data_pipeline/docker/.env
          echo "NAVER_CLIENT_ID=${{ secrets.NAVER_CLIENT_ID }}" >> data_pipeline/docker/.env
          echo "NAVER_CLIENT_SECRET=${{ secrets.NAVER_CLIENT_SECRET }}" >> data_pipeline/docker/.env
          echo "SLACK_WEBHOOK_URL=${{ secrets.SLACK_WEBHOOK_URL }}" >> data_pipeline/docker/.env

      # 4️⃣ .env 파일 EC2에 업로드 (경로 미리 생성된 상태)
      - name: Upload .env to EC2
        uses: appleboy/scp-action@v0.1.4
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          source: "data_pipeline/docker/.env"
          target: "~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/"

      # 5️⃣ 도커 컴포즈로 서비스 재시작
      - name: Run Docker Compose on EC2
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd ~/sportsdrink-pipeline-spark-airflow
            docker-compose -f data_pipeline/docker/docker-compose-airflow.yml \
                           -f data_pipeline/docker/docker-compose-postgres.yml \
                           up -d --build
