name: Auto Deploy to EC2 on Push

on:
  push:
    branches:
      - main  # main ë¸Œëœì¹˜ì— push ë  ë•Œ ì‹¤í–‰

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # 1ï¸âƒ£ GitHub ì½”ë“œ ì²´í¬ì•„ì›ƒ
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2ï¸âƒ£ EC2ì— Git í´ë¡  & ìµœì‹ í™”
      - name: Git clone or pull on EC2
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            # ğŸ“¦ í”„ë¡œì íŠ¸ clone or pull
            if [ ! -d ~/sportsdrink-pipeline-spark-airflow ]; then
              git clone https://github.com/deokjani/sportsdrink-pipeline-spark-airflow.git
            fi
            cd ~/sportsdrink-pipeline-spark-airflow
            git pull origin main
            
            # ğŸ“ .env íŒŒì¼ ìƒì„±
            mkdir -p ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker
            echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" > ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env
            echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env
            echo "NAVER_CLIENT_ID=${{ secrets.NAVER_CLIENT_ID }}" >> ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env
            echo "NAVER_CLIENT_SECRET=${{ secrets.NAVER_CLIENT_SECRET }}" >> ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env
            echo "SLACK_WEBHOOK_URL=${{ secrets.SLACK_WEBHOOK_URL }}" >> ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env
            echo "YOUTUBE_API_KEY=${{ secrets.YOUTUBE_API_KEY }}" >> ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env
            
            echo "âœ… EC2 ë‚´ .env íŒŒì¼ ìƒì„± ì™„ë£Œ"
            cat ~/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env

                        # ğŸ³ Docker Compose ì‹¤í–‰
            docker-compose -f data_pipeline/docker/docker-compose-airflow.yml \
                           -f data_pipeline/docker/docker-compose-postgres.yml \
                           up -d --build