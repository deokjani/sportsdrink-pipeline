import os
import pandas as pd
from datetime import datetime
from googleapiclient.discovery import build
from dotenv import load_dotenv

# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì—¬ê¸°ì— AWS ë° YouTube API KEYê°€ ì €ì¥ëœ .env íŒŒì¼ ê²½ë¡œ ì§€ì •)
load_dotenv(r"C:/project/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env")
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# âœ… YouTube API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)

# âœ… 1. ê²€ìƒ‰ì–´ë¡œ video_id ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ìˆì¸  ìš°ì„  ê²€ìƒ‰)
def get_video_id_by_keyword(keyword):
    search_response = youtube.search().list(
        q=keyword + " #shorts",
        part="snippet",
        type="video",
        order="relevance",
        maxResults=1
    ).execute()

    if search_response["items"]:
        video_id = search_response["items"][0]["id"]["videoId"]
        print(f"âœ… '{keyword}' ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ video_id: {video_id}")
        return video_id
    else:
        print(f"ğŸš¨ '{keyword}'ì— ëŒ€í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

# âœ… 2. íŠ¹ì • video_idì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_video_details(video_id):
    response = youtube.videos().list(
        part="snippet,statistics",
        id=video_id
    ).execute()

    if not response["items"]:
        print(f"ğŸš¨ video_id {video_id} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    item = response["items"][0]
    snippet = item["snippet"]
    stats = item["statistics"]

    video_data = {
        "video_id": video_id,
        "title": snippet["title"],
        "description": snippet["description"],
        "published_at": snippet["publishedAt"],
        "channel_id": snippet["channelId"],
        "channel_title": snippet["channelTitle"],
        "view_count": int(stats.get("viewCount", 0)),
        "like_count": int(stats.get("likeCount", 0)),
        "comment_count": int(stats.get("commentCount", 0)),
        "tags": snippet.get("tags", [])
    }
    return video_data

# âœ… 3. ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_channel_info(channel_id):
    response = youtube.channels().list(
        part="snippet,statistics",
        id=channel_id
    ).execute()

    if not response["items"]:
        print(f"ğŸš¨ channel_id {channel_id} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    item = response["items"][0]
    stats = item["statistics"]
    channel_data = {
        "channel_id": channel_id,
        "channel_title": item["snippet"]["title"],
        "subscriber_count": int(stats.get("subscriberCount", 0)),
        "total_views": int(stats.get("viewCount", 0)),
        "video_count": int(stats.get("videoCount", 0))
    }
    return channel_data

# âœ… 4. ì˜ìƒì˜ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
def get_video_comments(video_id, max_results=50):
    comments = []
    response = youtube.commentThreads().list(
        part="snippet",
        videoId=video_id,
        maxResults=max_results
    ).execute()

    for item in response["items"]:
        comment = item["snippet"]["topLevelComment"]["snippet"]
        comments.append({
            "video_id": video_id,
            "author": comment["authorDisplayName"],
            "comment_text": comment["textDisplay"],
            "published_at": comment["publishedAt"],
            "like_count": comment["likeCount"]
        })
    return comments

# âœ… 5. ì €ì¥ í•¨ìˆ˜ (ë‚ ì§œ í´ë” â†’ ì„œë¹„ìŠ¤ëª… í´ë” â†’ ë°ì´í„° ì¢…ë¥˜ í´ë”ì— ì €ì¥)
def save_to_folder(dataframe, root_dir, date_folder, service_folder, sub_folder_name):
    folder_path = os.path.join(root_dir, date_folder, service_folder, sub_folder_name)
    os.makedirs(folder_path, exist_ok=True)

    csv_path = os.path.join(folder_path, "data.csv")
    parquet_path = os.path.join(folder_path, "data.parquet")

    dataframe.to_csv(csv_path, index=False, encoding="utf-8-sig")
    dataframe.to_parquet(parquet_path, index=False)

    print(f"âœ… '{sub_folder_name}' ì €ì¥ ì™„ë£Œ:\n{csv_path}\n{parquet_path}")

# âœ… 6. ì‹¤í–‰
if __name__ == "__main__":
    search_keyword = "ì´ì˜¨ìŒë£Œ ì¶”ì²œ"  # ë¶„ì„í•  í‚¤ì›Œë“œ

    # âœ… ê²½ë¡œ ë° í´ë”ëª… ì •ë³´
    save_root_dir = "C:/project/sportsdrink-pipeline-spark-airflow/data_pipeline/data/raw/"
    service_name = "sportsdrink"  # ì„œë¹„ìŠ¤ëª…
    data_source = "youtube"  # ë°ì´í„° ì¶œì²˜ (ex: Twitter, Naver, YouTube ë“±)
    data_type = "search"  # ë°ì´í„° ì„±ê²© (ex: Search, Sales, Trend, Log ë“±)
    batch_cycle = "daily"  # ë°°ì¹˜ ì£¼ê¸° (ex: Hourly, Daily, Weekly, Monthly)
    date_str = datetime.now().strftime('%Y%m%d')  # ë‚ ì§œ í´ë” ìƒì„±ìš©

    # ë‚ ì§œ ë° ì„œë¹„ìŠ¤ëª… í´ë”ëª…
    date_folder = date_str
    service_folder = f"{service_name}_{data_source}_{data_type}_{batch_cycle}"

    # âœ… video_id ê°€ì ¸ì˜¤ê¸°
    video_id = get_video_id_by_keyword(search_keyword)

    if video_id:
        print("\nğŸ” ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        video_data = get_video_details(video_id)
        video_df = pd.DataFrame([video_data])
        save_to_folder(video_df, save_root_dir, date_folder, service_folder, "video_info")

        print("\nğŸ” ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        channel_info = get_channel_info(video_data["channel_id"])
        channel_df = pd.DataFrame([channel_info])
        save_to_folder(channel_df, save_root_dir, date_folder, service_folder, "channel_info")

        print("\nğŸ” ëŒ“ê¸€ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        comments = get_video_comments(video_id, max_results=30)
        comments_df = pd.DataFrame(comments)
        save_to_folder(comments_df, save_root_dir, date_folder, service_folder, "comments")

    else:
        print("âš ï¸ video_idë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
