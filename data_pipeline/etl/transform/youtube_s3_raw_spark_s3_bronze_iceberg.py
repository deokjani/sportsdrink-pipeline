import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, trim, to_date, expr, length, concat_ws
from dotenv import load_dotenv
from datetime import datetime

# âœ… 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(r"C:/ITWILL/SportsDrinkForecast/docker-elk/.env")

# âœ… 2) Spark ì„¸ì…˜ ìƒì„± (Iceberg + S3 ì—°ë™)
spark = (
    SparkSession.builder
    .appName("YouTube S3 Raw Transform to Iceberg")
    .config("spark.jars.packages",
            ",".join([
                "org.apache.hadoop:hadoop-aws:3.3.4",
                "org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.3"
            ]))
    .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions")
    .config("spark.sql.catalog.hadoop_hms", "org.apache.iceberg.spark.SparkCatalog")
    .config("spark.sql.catalog.hadoop_hms.catalog-impl", "org.apache.iceberg.hive.HiveCatalog")
    .config("spark.sql.catalog.hadoop_hms.uri", "thrift://localhost:9083")
    .config("spark.sql.catalog.hadoop_hms.warehouse", "s3a://deokjin-test-datalake/data/")
    .config("spark.hadoop.fs.s3a.access.key", os.getenv("AWS_ACCESS_KEY_ID"))
    .config("spark.hadoop.fs.s3a.secret.key", os.getenv("AWS_SECRET_ACCESS_KEY"))
    .config("spark.hadoop.fs.s3a.endpoint", "s3.ap-northeast-2.amazonaws.com")
    .getOrCreate()
)

spark.sparkContext.setLogLevel("WARN")

# âœ… 3) ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_namespace_if_not_exists(namespace):
    spark.sql(f"CREATE NAMESPACE IF NOT EXISTS hadoop_hms.{namespace}")
    print(f"âœ… ë„¤ì„ìŠ¤í˜ì´ìŠ¤ '{namespace}' ìƒì„± ì™„ë£Œ!")

# âœ… 4) ë‚ ì§œ ë° ì„œë¹„ìŠ¤ëª… ì„¸íŒ…
target_date = "20250322"
service_folder = "sportsdrink_youtube_search_daily"

# âœ… 5) S3 ì›ë³¸ ë°ì´í„° ê²½ë¡œ ì„¸íŒ…
base_path = f"s3a://deokjin-test-datalake/data/raw/{target_date}/{service_folder}"
channel_info_path = f"{base_path}/channel_info/data.parquet"
video_info_path = f"{base_path}/video_info/data.parquet"
comments_info_path = f"{base_path}/comments/data.parquet"

# âœ… 6) ì›ë³¸ ë°ì´í„° ë¡œë“œ
channel_info_df = spark.read.parquet(channel_info_path)
video_info_df = spark.read.parquet(video_info_path)
comments_info_df = spark.read.parquet(comments_info_path)

# âœ… 7) ê³µí†µ í´ë¦°ì—… í•¨ìˆ˜
def clean_and_add_date_column(df):
    for c, dtype in df.dtypes:
        if dtype == "string":
            df = df.withColumn(c, trim(col(c)))
        elif dtype.startswith("array"):
            df = df.withColumn(c, concat_ws(",", col(c)))
    df = df.withColumn("crawled_date", expr(f"'{datetime.today().strftime('%Y-%m-%d')}'"))
    return df

# âœ… 8) ë‚ ì§œ íŒŒí‹°ì…˜ ì»¬ëŸ¼ ë³€í™˜
def add_partition_columns(df):
    return df.withColumn("crawled_date", to_date(col("crawled_date")))

# âœ… 9) ì´ìƒì¹˜ ì œê±° í•¨ìˆ˜
def remove_outliers(df, conditions_dict):
    for column_name, condition in conditions_dict.items():
        df = df.filter(expr(f"{column_name} {condition}"))
    return df

# âœ… 10) ì§§ì€ í…ìŠ¤íŠ¸ ì œê±° í•¨ìˆ˜
def remove_short_text(df, column_name, min_length=3):
    return df.filter(length(col(column_name)) >= min_length)

# âœ… 11) Iceberg í…Œì´ë¸” ì €ì¥ í•¨ìˆ˜ (ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±ì€ ì™¸ë¶€ì—ì„œ í•œ ë²ˆë§Œ!)
def save_to_iceberg_table(df, namespace, table_name):
    df.writeTo(f"hadoop_hms.{namespace}.{table_name}") \
      .using("iceberg") \
      .tableProperty("format-version", "2") \
      .createOrReplace()

    print(f"âœ… Iceberg í…Œì´ë¸” '{namespace}.{table_name}' ì €ì¥ ì™„ë£Œ!")

# âœ… 12) ë°ì´í„° í´ë¦° ë° ë³€í™˜
channel_info_clean = add_partition_columns(remove_outliers(clean_and_add_date_column(channel_info_df), {
    "subscriber_count": ">= 0", "total_views": ">= 0", "video_count": ">= 0"
}))

video_info_clean = add_partition_columns(remove_outliers(remove_short_text(
    clean_and_add_date_column(video_info_df), "title", min_length=3), {
    "view_count": ">= 0", "like_count": ">= 0", "comment_count": ">= 0"
}))

comments_info_clean = add_partition_columns(remove_outliers(remove_short_text(
    clean_and_add_date_column(comments_info_df), "comment_text", min_length=3), {
    "like_count": ">= 0"
}))

# âœ… ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± (ë”± í•œ ë²ˆë§Œ!)
namespace = f"{service_folder}_bronze"
create_namespace_if_not_exists(namespace)

# âœ… í…Œì´ë¸” ì €ì¥
save_to_iceberg_table(channel_info_clean, namespace, "channel_info")
save_to_iceberg_table(video_info_clean, namespace, "video_info")
save_to_iceberg_table(comments_info_clean, namespace, "comments_info")

print("\nğŸ‰ ëª¨ë“  Iceberg í…Œì´ë¸” ì €ì¥ ì™„ë£Œ!")

# âœ… 13) Spark ì„¸ì…˜ ì¢…ë£Œ
spark.stop()
