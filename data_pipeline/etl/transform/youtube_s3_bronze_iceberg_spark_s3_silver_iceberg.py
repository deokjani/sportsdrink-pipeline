import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, length, when, lit, current_date
from dotenv import load_dotenv

# âœ… 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(r"C:/project/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/.env")
env = os.getenv("ENV", "dev")  # ê¸°ë³¸ê°’ì€ dev

# âœ… 2) Spark ì„¸ì…˜ ìƒì„± (ì •ì  ì„¤ì •)
spark = (
    SparkSession.builder
    .appName("Bronze â†’ Silver (Feature Store) transform pipeline")
    .config("spark.jars.packages",
            ",".join([
                "org.apache.hadoop:hadoop-aws:3.3.4",
                "org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.3"
            ]))
    .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions")
    .config("spark.sql.catalog.hadoop_hms", "org.apache.iceberg.spark.SparkCatalog")
    .config("spark.sql.catalog.hadoop_hms.catalog-impl", "org.apache.iceberg.hive.HiveCatalog")
    .config("spark.sql.catalog.hadoop_hms.uri", "thrift://localhost:9083")
    .config("spark.sql.catalog.hadoop_hms.warehouse", f"s3a://deokjin-test-datalake/data/{env}/")
    .config("spark.hadoop.fs.s3a.access.key", os.getenv("AWS_ACCESS_KEY_ID"))
    .config("spark.hadoop.fs.s3a.secret.key", os.getenv("AWS_SECRET_ACCESS_KEY"))
    .config("spark.hadoop.fs.s3a.endpoint", "s3.ap-northeast-2.amazonaws.com")
    .getOrCreate()
)

spark.sparkContext.setLogLevel("WARN")

# âœ… (ê³µí†µ) ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± í•¨ìˆ˜
def create_namespace_if_not_exists(namespace):
    spark.sql(f"CREATE NAMESPACE IF NOT EXISTS hadoop_hms.{namespace}")
    print(f"âœ… ë„¤ì„ìŠ¤í˜ì´ìŠ¤ '{namespace}' ìƒì„± ì™„ë£Œ!")

# âœ… (ê³µí†µ) feature í…Œì´ë¸” ì €ì¥ í•¨ìˆ˜ (ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ + feature_date ì¶”ê°€)
def save_feature_table(df, namespace, table_name):
    full_table_name = f"hadoop_hms.{namespace}.{table_name}"
    df = df.withColumn("feature_date", current_date())

    df.writeTo(full_table_name).createOrReplace()
    print(f"âœ… {namespace}.{table_name} ì €ì¥ ì™„ë£Œ!")

# âœ… 3) Bronze (1ì°¨ ì •ì œ ë°ì´í„°) í…Œì´ë¸” ë¡œë“œ
bronze_namespace = "sportsdrink_youtube_search_daily_bronze"
channel_info = spark.read.format("iceberg").load(f"hadoop_hms.{bronze_namespace}.channel_info")
video_info = spark.read.format("iceberg").load(f"hadoop_hms.{bronze_namespace}.video_info")
comments_info = spark.read.format("iceberg").load(f"hadoop_hms.{bronze_namespace}.comments_info")

# âœ… 4) Silver ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± (í•œ ë²ˆë§Œ)
silver_namespace = "sportsdrink_youtube_search_daily_silver"
create_namespace_if_not_exists(silver_namespace)

# âœ… 5) comments_feature ìƒì„± ë° ì €ì¥
comments_features = comments_info \
    .withColumn("comment_length", length(col("comment_text"))) \
    .withColumn("is_highlighted",
                when((col("like_count").cast("int") > 50) & (length(col("comment_text")) > 20), lit(1)).otherwise(lit(0))) \
    .withColumn("sentiment_flag",
                when(col("comment_text").rlike("good|great|nice|awesome|ğŸ‘"), lit(1)).otherwise(lit(0)))
save_feature_table(comments_features, silver_namespace, "comments_feature")

# âœ… 6) channel_feature ìƒì„± ë° ì €ì¥
channel_features = channel_info.withColumn(
    "is_big_channel",
    when(col("subscriber_count").cast("int") > 100000, lit(1)).otherwise(lit(0))
).withColumn(
    "channel_tier",
    when(col("subscriber_count").cast("int") > 1000000, lit("platinum"))
    .when(col("subscriber_count").cast("int") > 100000, lit("gold"))
    .when(col("subscriber_count").cast("int") > 10000, lit("silver"))
    .otherwise(lit("bronze"))
)
save_feature_table(channel_features, silver_namespace, "channel_feature")

# âœ… 7) video_feature ìƒì„± ë° ì €ì¥
video_features = video_info \
    .withColumn("like_to_view_ratio", (col("like_count").cast("float") / (col("view_count").cast("float") + 1))) \
    .withColumn("comment_to_view_ratio", (col("comment_count").cast("float") / (col("view_count").cast("float") + 1))) \
    .withColumn("engagement_score", (
        (col("like_count").cast("float") * 2 + col("comment_count").cast("float")) / (
            col("view_count").cast("float") + 1)
))
save_feature_table(video_features, silver_namespace, "video_feature")

# âœ… ì™„ë£Œ ë¡œê·¸ ì¶œë ¥
print("\nğŸ‰ Bronze â†’ Silver (Feature Store) íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")

spark.stop()
