import os
from pyspark.sql import SparkSession

# âœ… 1. Spark ì„¸ì…˜ ìƒì„±
spark = (
    SparkSession.builder
    .appName("Preview Feature Sample")
    .getOrCreate()
)
spark.sparkContext.setLogLevel("WARN")

# âœ… 2. ì €ì¥ëœ Parquet ê²½ë¡œ
PARQUET_PATH = r"C:/project/sportsdrink-pipeline-spark-airflow/data_pipeline/data/features/sportsdrink_youtube_search_daily/feature_date=2025-03-30"
SAVE_CSV_PATH = r"C:/project/sportsdrink-pipeline-spark-airflow/data_pipeline/data/features/sample_feature_preview.csv"

# âœ… 3. Parquet ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = spark.read.parquet(PARQUET_PATH)

# âœ… 4. ìƒìœ„ 5ê°œ row ì½˜ì†”ì— ì¶œë ¥
print("\nğŸ§¾ Feature ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ í–‰):\n")
df.show(5, truncate=False)

# âœ… 5. ì¼ë¶€ ìƒ˜í”Œë§Œ CSVë¡œ ì €ì¥ (ìµœëŒ€ 100ê°œ í–‰)
# df.limit(100).coalesce(1).write.option("header", True).mode("overwrite").csv(SAVE_CSV_PATH)

# âœ… 6. ì™„ë£Œ ë©”ì‹œì§€
# print(f"\nğŸ“ CSV ìƒ˜í”Œ ì €ì¥ ì™„ë£Œ! â†’ {SAVE_CSV_PATH}")

spark.stop()
