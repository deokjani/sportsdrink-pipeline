from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
import subprocess
import os
import requests  # âœ… Slack ë©”ì‹œì§€ ì „ì†¡ì„ ìœ„í•œ requests ëª¨ë“ˆ

# âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
BASE_PATH = os.getenv("BASE_PATH", "/opt/airflow/data_pipeline")
SLACK_WEBHOOK_URL = os.getenv("SLACK_WEBHOOK_URL")

# âœ… Slack ì•Œë¦¼ í•¨ìˆ˜
def send_slack_alert(context):
    """Slackìœ¼ë¡œ DAG ì‹¤íŒ¨ ë˜ëŠ” ì„±ê³µ ì•Œë¦¼ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜"""
    if not SLACK_WEBHOOK_URL:
        print("âŒ SLACK_WEBHOOK_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    task_instance = context.get("task_instance")
    dag_id = context.get("dag").dag_id
    task_id = task_instance.task_id
    execution_date = context.get("execution_date")
    log_url = task_instance.log_url

    status = context.get("state")  # 'success' ë˜ëŠ” 'failed'
    emoji = ":white_check_mark:" if status == "success" else ":x:"
    color = "good" if status == "success" else "danger"

    message = {
        "attachments": [
            {
                "color": color,
                "title": f"{emoji} Airflow DAG Alert",
                "fields": [
                    {"title": "DAG ID", "value": dag_id, "short": True},
                    {"title": "Task ID", "value": task_id, "short": True},
                    {"title": "Execution Date", "value": str(execution_date), "short": False},
                    {"title": "Status", "value": status.upper(), "short": True},
                    {"title": "Logs", "value": f"<{log_url}|View Logs>", "short": False},
                ],
            }
        ]
    }

    response = requests.post(SLACK_WEBHOOK_URL, json=message)

    if response.status_code == 200:
        print("âœ… Slack ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
    else:
        print(f"âŒ Slack ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.text}")

# âœ… DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "start_date": datetime(2024, 3, 7),
    "retries": 0,
    "retry_delay": timedelta(minutes=5),
    "on_failure_callback": send_slack_alert,  # DAG ì‹¤íŒ¨ ì‹œ Slack ì•Œë¦¼
}

# âœ… DAG ì •ì˜
dag = DAG(
    "naver_sports_drink_etl_daily_dag",
    default_args=default_args,
    description="ë„¤ì´ë²„ ê²€ìƒ‰ API ë°ì´í„° ìˆ˜ì§‘ â†’ Parquet ì²˜ë¦¬ â†’ S3 ì €ì¥",
    schedule_interval="0 8 * * *",  # ë§¤ì¼ ì•„ì¹¨ 8ì‹œ ì‹¤í–‰
    catchup=False,
    max_active_runs=1,
)

# âœ… Python íŒŒì¼ ì‹¤í–‰ í•¨ìˆ˜
def run_script(script_folder, script_name, **kwargs):
    """Python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    script_path = os.path.join(BASE_PATH, script_folder, script_name)
    print(f"ğŸš€ ì‹¤í–‰ ì‹œì‘: {script_path}")

    try:
        result = subprocess.run(["python", script_path], check=True, text=True, capture_output=True)
        print(f"âœ… {script_name} ì‹¤í–‰ ê²°ê³¼:\n{result.stdout}")

        if result.stderr:
            print(f"âš ï¸ {script_name} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:\n{result.stderr}")

        # âœ… ì„±ê³µ ì‹œ Slack ë©”ì‹œì§€ ì „ì†¡
        send_slack_alert({
            "task_instance": kwargs.get("task_instance"),
            "dag": kwargs.get("dag"),
            "execution_date": kwargs.get("execution_date"),
            "state": "success",
        })
    except subprocess.CalledProcessError as e:
        print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {script_name}\n{e.stderr}")

        # âœ… ì‹¤íŒ¨ ì‹œ Slack ë©”ì‹œì§€ ì „ì†¡
        send_slack_alert({
            "task_instance": kwargs.get("task_instance"),
            "dag": kwargs.get("dag"),
            "execution_date": kwargs.get("execution_date"),
            "state": "failed",
        })
        raise

# âœ… Task 1: ë„¤ì´ë²„ ê²€ìƒ‰ API ë°ì´í„° ìˆ˜ì§‘ (PostgreSQL ì €ì¥)
task_naver_sports_drink_to_postgresql = PythonOperator(
    task_id="naver_sports_drink_to_postgresql",
    python_callable=run_script,
    op_kwargs={"script_folder": "etl/extract", "script_name": "naver_sports_drink_to_postgresql.py"},
    dag=dag,
    on_success_callback=send_slack_alert,  # ì„±ê³µ ì‹œ Slack ì•Œë¦¼
    on_failure_callback=send_slack_alert,  # ì‹¤íŒ¨ ì‹œ Slack ì•Œë¦¼
)

# âœ… Task 2: PostgreSQL ë°ì´í„° Parquetë¡œ ë³€í™˜
task_naver_sports_drink_postgresql_to_parquet = PythonOperator(
    task_id="naver_sports_drink_postgresql_to_parquet",
    python_callable=run_script,
    op_kwargs={"script_folder": "etl/transform", "script_name": "naver_sports_drink_postgresql_to_parquet.py"},
    dag=dag,
    on_success_callback=send_slack_alert,  # ì„±ê³µ ì‹œ Slack ì•Œë¦¼
    on_failure_callback=send_slack_alert,  # ì‹¤íŒ¨ ì‹œ Slack ì•Œë¦¼
)

# âœ… Task 3: Parquet ë³€í™˜ ë° S3 ì—…ë¡œë“œ
task_naver_sports_drink_upload_parquet_to_s3 = PythonOperator(
    task_id="naver_sports_drink_upload_parquet_to_s3",
    python_callable=run_script,
    op_kwargs={"script_folder": "etl/load", "script_name": "naver_sports_drink_upload_parquet_to_s3.py"},
    dag=dag,
    on_success_callback=send_slack_alert,  # ì„±ê³µ ì‹œ Slack ì•Œë¦¼
    on_failure_callback=send_slack_alert,  # ì‹¤íŒ¨ ì‹œ Slack ì•Œë¦¼
)

# âœ… ì‹¤í–‰ ìˆœì„œ ì •ì˜
task_naver_sports_drink_to_postgresql >> task_naver_sports_drink_postgresql_to_parquet >> task_naver_sports_drink_upload_parquet_to_s3
