version: '3.8'

services:
  # 1️⃣ Elasticsearch (데이터 저장소)
  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    image: docker.elastic.co/elasticsearch/elasticsearch-custom:8.17.1  
    container_name: elasticsearch      
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch_data:/usr/share/elasticsearch/data:Z
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      discovery.type: single-node
    networks:
      - elk
    restart: unless-stopped

  # 2️⃣ Logstash (데이터 수집 및 가공)
  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    image: docker.elastic.co/logstash/logstash-custom:8.17.1    
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro,Z
      - logstash_data:/usr/share/logstash/data
    ports:
      - "5044:5044"  # Filebeat → Logstash (Beats Input)
      - "50000:50000/tcp"
      - "50000:50000/udp"
      - "9600:9600"  # Logstash API 포트
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}  # ✅ 환경 변수 참조
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # 3️⃣ Kibana (데이터 시각화)
  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    image: docker.elastic.co/kibana/kibana-custom:8.17.1    
    container_name: kibana    
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

networks:
  elk:
    driver: bridge

volumes:
  elasticsearch_data:
  logstash_data:

# 1
# docker network prune -f / docker builder prune -af
# docker-compose -f docker-compose-elk.yml down
# docker-compose -f docker-compose-elk.yml build --no-cache
# docker-compose -f docker-compose-elk.yml up -d
