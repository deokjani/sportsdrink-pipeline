version: '3.8'

services:
  airflow:
    build: ./airflow
    image: apache/airflow-custom:2.7.3
    container_name: airflow
    restart: unless-stopped
    env_file:
      - .env  # ✅ 이 한 줄로 모든 환경변수 자동 주입!
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__DAG_DISCOVERY_SAFE_MODE=False
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Seoul
      - TZ=Asia/Seoul
      - AIRFLOW__LOGGING__LOG_FILENAME_TEMPLATE={{ ti.dag_id }}/{{ (execution_date + macros.timedelta(hours=9)).strftime("%Y-%m-%d_%H-%M-%S") }}_{{ ti.task_id }}.log
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://progress:progress@progress-db:5432/airflow_db
      - AIRFLOW__WEBSERVER__DEFAULT_USER=admin
      - AIRFLOW__WEBSERVER__DEFAULT_PASSWORD=admin
    ports:
      - "8080:8080"
    volumes:
      - airflow_dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_config:/opt/airflow/config
      - ./airflow/dags:/opt/airflow/dags:rw
      - ./airflow/logs:/opt/airflow/logs:rw
      - ./airflow/data_pipeline:/opt/airflow/data_pipeline:rw
      - ./data/processed:/opt/airflow/data/processed:rw
      # scp -i "C:/Users/topcd/.ssh/deokjani-ec2-key.pem" C:/project/sportsdrink-pipeline-spark-airflow/data_pipeline/docker/airflow/setup_airflow.sh ubuntu@43.201.77.96:~/
      # ssh -i "C:/Users/topcd/.ssh/deokjani-ec2-key.pem" ubuntu@43.201.77.96
      # chmod +x setup_airflow.sh
      # ./setup_airflow.sh
      # git action 실행 > git 코드 push
      # cd ~/sportsdrink-pipeline-spark-airflow
      # docker compose docker-compose-postgres.yml up -d --build
      # --------------- airflow까지 실행하기에 ec2 메모리 부족으로 postgres만 빌드함.. ----------------

      # docker compose -f docker-compose-airflow.yml -f docker-compose-postgres.yml up -d --build
      # docker compose -f docker-compose-airflow.yml -f docker-compose-postgres.yml down
      # sudo chmod -R 777 ./airflow/dags ./airflow/logs ./airflow/config ./airflow/scripts
      # docker compose -f docker-compose-airflow.yml -f docker-compose-postgres.yml up -d
      # docker logs airflow
    networks:
      - elk
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username admin --password admin --role Admin --email admin@example.com --firstname admin --lastname user &&
               airflow scheduler & airflow webserver"
networks:
  elk:
    driver: bridge

volumes:
  airflow_dags:
  airflow_logs:
  airflow_config:


# 3   
# docker-compose -f docker-compose-airflow.yml down
# docker-compose -f docker-compose-airflow.yml build --no-cache
# docker-compose -f docker-compose-airflow.yml up -d
